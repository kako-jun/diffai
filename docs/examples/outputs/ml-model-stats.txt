# diffai Demo Output: ml-model-stats
# Description: ML model comparison with comprehensive analysis (statistics included automatically)
# Command: diffai tests/fixtures/ml_models/simple_base.safetensors tests/fixtures/ml_models/simple_modified.safetensors
# Generated: Mon Jul 14 02:10:44 PM JST 2025
# Version: 0.3.4

## Command Output:

anomaly_detection: type=missing_layer, severity=medium, action="monitor_closely_adjust_hyperparameters", regression_test=regression_test_required
architecture_comparison: type1=feedforward, type2=feedforward, depth=2→6, differences=10, deployment_readiness=not_ready, "thorough_testing_required"
change_summary: layers_changed=8, magnitude=2.0000, patterns=2, most_changed=5
+ convergence_analysis: status=plateaued, stability=1.0000, inference_speed=⚡ (convergence)
gradient_analysis: flow_health=vanishing, norm=0.000000, ratio=1.0000
memory_analysis: delta=+0.0MB, gpu_est=0.1MB, efficiency=0.015470, review_friendly="optimal_no_action_needed", "optimal_no_action_needed"
◦ quantization_analysis: compression=0.0%, speedup=1.8x, precision_loss=1.5%, suitability=good (quantization)
regression_test: passed=true, degradation=-2.5%, severity=low, "proceed_with_deployment"
  - fc.bias: shape=[5], dtype=f32, params=5
  - fc.weight: shape=[5, 10], dtype=f32, params=50
  + fc1.bias: shape=[64], dtype=f32, params=64
  + fc1.weight: shape=[64, 128], dtype=f32, params=8192
  + fc2.bias: shape=[32], dtype=f32, params=32
  + fc2.weight: shape=[32, 64], dtype=f32, params=2048
  + fc3.bias: shape=[10], dtype=f32, params=10
  + fc3.weight: shape=[10, 32], dtype=f32, params=320
